{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import obspy\n",
    "from obspy import read\n",
    "from obspy.signal.trigger import recursive_sta_lta, classic_sta_lta#, carl_sta_lta\n",
    "from obspy.signal.trigger import plot_trigger, trigger_onset\n",
    "from scipy.signal import butter, filtfilt, wiener, stft\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Input, Lambda, Concatenate\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    st = read(file_path)\n",
    "    x = st[0].data\n",
    "    arrival_time = st[0].stats.starttime.timestamp\n",
    "    y = np.zeros_like(x)\n",
    "    y[int(arrival_time)] = 1\n",
    "    return x, y\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def preprocess_data(x, fs=100):\n",
    "    x = bandpass_filter(x, 1.0, 10.0, fs)\n",
    "    x = wiener(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the STA/LTA Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sta_lta(data, nsta, nlta, method='recursive'):\n",
    "    if method == 'recursive':\n",
    "        sta_lta = recursive_sta_lta(data, nsta, nlta)\n",
    "    elif method == 'classic':\n",
    "        sta_lta = classic_sta_lta(data, nsta, nlta)\n",
    "    #elif method == 'carl':\n",
    "        #sta_lta = carl_sta_lta(data, nsta, nlta)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported STA/LTA method\")\n",
    "    return sta_lta\n",
    "\n",
    "def apply_stft(data, fs=100, nperseg=256):\n",
    "    f, t, Zxx = stft(data, fs=fs, nperseg=nperseg)\n",
    "    return np.abs(Zxx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the 1D CNN Model with Learnable STA/LTA Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # Learnable STA/LTA windows\n",
    "    nsta = Dense(1, activation='relu', name='nsta')(input_layer)\n",
    "    nlta = Dense(1, activation='relu', name='nlta')(input_layer)\n",
    "    \n",
    "    # Apply STA/LTA\n",
    "    sta_lta_layer = Lambda(lambda x: apply_sta_lta(x[0], K.cast(x[1], 'int32'), K.cast(x[2], 'int32')), name='sta_lta')([input_layer, nsta, nlta])\n",
    "\n",
    "    # Apply STFT\n",
    "    stft_layer = Lambda(lambda x: apply_stft(x), name='stft')(input_layer)\n",
    "\n",
    "    # Combine STA/LTA and STFT\n",
    "    combined = Concatenate()([sta_lta_layer, stft_layer])\n",
    "    \n",
    "    # CNN layers\n",
    "    conv1 = Conv1D(16, kernel_size=3, activation='relu')(sta_lta_layer)\n",
    "    #conv1 = Conv1D(16, kernel_size=3, activation='relu')(combined)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "    conv2 = Conv1D(32, kernel_size=3, activation='relu')(pool1)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "    flat = Flatten()(pool2)\n",
    "    dense1 = Dense(64, activation='relu')(flat)\n",
    "    output_layer = Dense(1, activation='sigmoid')(dense1)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    weight = tf.where(tf.equal(y_true, 1), 10.0, 1.0)\n",
    "    return loss * weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train, epochs=50, batch_size=32):\n",
    "    model.compile(optimizer='adam', loss=custom_loss, metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test):    \n",
    "    # Use model.evaluate to get the loss and accuracy\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f'Test Loss: {loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # Predict the output for the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    # Compute additional metrics\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'Test Precision: {precision:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')\n",
    "    print(f'Test F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess data\n",
    "x, y = load_data('data.mseed')\n",
    "x = preprocess_data(x)\n",
    "\n",
    "# Reshape data for CNN\n",
    "x = x.reshape(-1, len(x), 1)\n",
    "y = y.reshape(-1, len(y), 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n",
    "x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n",
    "\n",
    "# Create and train the model\n",
    "model = create_model(input_shape=(x_train.shape[1], 1))\n",
    "train_model(model, x_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
